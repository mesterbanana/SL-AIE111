{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available:\", cuda_available)\n",
    "\n",
    "if cuda_available:\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "    print(\"Current CUDA Device:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting training...\n",
      "Epoch 1/50\n",
      "  Train Loss: 0.2394, Train Accuracy: 93.00%\n",
      "  Val Loss: 0.0839, Val Accuracy: 97.40%\n",
      "Epoch 2/50\n",
      "  Train Loss: 0.1108, Train Accuracy: 96.80%\n",
      "  Val Loss: 0.1819, Val Accuracy: 94.78%\n",
      "Epoch 3/50\n",
      "  Train Loss: 0.0819, Train Accuracy: 97.59%\n",
      "  Val Loss: 0.0443, Val Accuracy: 98.69%\n",
      "Epoch 4/50\n",
      "  Train Loss: 0.0669, Train Accuracy: 98.06%\n",
      "  Val Loss: 0.1099, Val Accuracy: 97.37%\n",
      "Epoch 5/50\n",
      "  Train Loss: 0.0603, Train Accuracy: 98.22%\n",
      "  Val Loss: 0.0354, Val Accuracy: 99.04%\n",
      "Epoch 6/50\n",
      "  Train Loss: 0.0182, Train Accuracy: 99.46%\n",
      "  Val Loss: 0.0158, Val Accuracy: 99.56%\n",
      "Epoch 7/50\n",
      "  Train Loss: 0.0090, Train Accuracy: 99.74%\n",
      "  Val Loss: 0.0133, Val Accuracy: 99.64%\n",
      "Epoch 8/50\n",
      "  Train Loss: 0.0052, Train Accuracy: 99.84%\n",
      "  Val Loss: 0.0122, Val Accuracy: 99.67%\n",
      "Epoch 9/50\n",
      "  Train Loss: 0.0035, Train Accuracy: 99.88%\n",
      "  Val Loss: 0.0115, Val Accuracy: 99.70%\n",
      "Epoch 10/50\n",
      "  Train Loss: 0.0024, Train Accuracy: 99.94%\n",
      "  Val Loss: 0.0117, Val Accuracy: 99.68%\n",
      "Epoch 11/50\n",
      "  Train Loss: 0.0016, Train Accuracy: 99.96%\n",
      "  Val Loss: 0.0103, Val Accuracy: 99.72%\n",
      "Epoch 12/50\n",
      "  Train Loss: 0.0011, Train Accuracy: 99.97%\n",
      "  Val Loss: 0.0102, Val Accuracy: 99.76%\n",
      "Epoch 13/50\n",
      "  Train Loss: 0.0009, Train Accuracy: 99.97%\n",
      "  Val Loss: 0.0101, Val Accuracy: 99.77%\n",
      "Epoch 14/50\n",
      "  Train Loss: 0.0008, Train Accuracy: 99.98%\n",
      "  Val Loss: 0.0107, Val Accuracy: 99.77%\n",
      "Epoch 15/50\n",
      "  Train Loss: 0.0007, Train Accuracy: 99.98%\n",
      "  Val Loss: 0.0104, Val Accuracy: 99.75%\n",
      "Epoch 16/50\n",
      "  Train Loss: 0.0007, Train Accuracy: 99.97%\n",
      "  Val Loss: 0.0108, Val Accuracy: 99.75%\n",
      "Epoch 17/50\n",
      "  Train Loss: 0.0007, Train Accuracy: 99.98%\n",
      "  Val Loss: 0.0103, Val Accuracy: 99.77%\n",
      "Epoch 18/50\n",
      "  Train Loss: 0.0006, Train Accuracy: 99.98%\n",
      "  Val Loss: 0.0104, Val Accuracy: 99.77%\n",
      "Epoch 19/50\n",
      "  Train Loss: 0.0007, Train Accuracy: 99.97%\n",
      "  Val Loss: 0.0102, Val Accuracy: 99.76%\n",
      "Early stopping triggered.\n",
      "Training complete. Model saved to /home/mostafabakr/Desktop/Project X/Final_models/asl_image_model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "\n",
    "dataset_dir = \"/home/mostafabakr/Desktop/Project X/Test_img/detected_hands\"  \n",
    "video_dataset_dir = \"/home/mostafabakr/Desktop/Project X/vid data\"  \n",
    "frame_output_dir = \"/home/mostafabakr/Desktop/Project X/Test_img/frames\"  \n",
    "save_image_model_path = \"/home/mostafabakr/Desktop/Project X/Final_models/asl_image_model.pth\"\n",
    "save_video_model_path = \"/home/mostafabakr/Desktop/Project X/Final_models/asl_video_model.pth\"\n",
    "img_size = 224\n",
    "batch_size = 16\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "validation_split = 0.2\n",
    "patience = 5\n",
    "frame_rate = 5 \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(dataset_dir, save_model_path):\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        raise FileNotFoundError(f\"Dataset directory '{dataset_dir}' not found.\")\n",
    "    \n",
    "    dataset = datasets.ImageFolder(root=dataset_dir, transform=transform)\n",
    "    val_size = int(len(dataset) * validation_split)\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    class_names = dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    weights = MobileNet_V2_Weights.IMAGENET1K_V1\n",
    "    model = models.mobilenet_v2(weights=weights)\n",
    "    model.classifier[1] = nn.Linear(model.last_channel, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct / total * 100\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = val_correct / val_total * 100\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    torch.save(model.state_dict(), save_model_path)\n",
    "    print(f\"Training complete. Model saved to {save_model_path}\")\n",
    "\n",
    "def extract_frames(video_dataset_dir, output_dir, frame_rate=60):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for label_dir in os.listdir(video_dataset_dir):\n",
    "        label_path = os.path.join(video_dataset_dir, label_dir)\n",
    "        output_label_dir = os.path.join(output_dir, label_dir)\n",
    "        os.makedirs(output_label_dir, exist_ok=True)\n",
    "\n",
    "        for video_file in os.listdir(label_path):\n",
    "            video_path = os.path.join(label_path, video_file)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frame_count = 0\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                if frame_count % frame_rate == 0:\n",
    "                    frame_filename = os.path.join(\n",
    "                        output_label_dir, f\"{os.path.splitext(video_file)[0]}_frame_{frame_count}.jpg\"\n",
    "                    )\n",
    "                    cv2.imwrite(frame_filename, frame)\n",
    "                frame_count += 1\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "    print(\"Frame extraction complete.\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(dataset_dir, save_image_model_path)\n",
    "\n",
    "    extract_frames(video_dataset_dir, frame_output_dir)\n",
    "    train_model(frame_output_dir, save_video_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
